{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJ+hmM4UwOpZB33OGa/yHT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SonOf1998/ProblemSet4/blob/main/ps4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12d3fx_kHIrn"
      },
      "source": [
        "First install the package that makes it easy to get the required images.\n",
        "Unfortunately it implicitly installs tensorflow-cpu and it makes the google colab doing its computations on CPU even if I set the runtime type! Uninstalling and reinstalling tensorflow in an additional cell solves the problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVxZMlVz5Qh6"
      },
      "source": [
        "!pip install openimages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndagihTPnWy9"
      },
      "source": [
        "!pip uninstall --yes tensorflow-cpu\n",
        "!pip uninstall --yes tensorflow\n",
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ox24f8e5j1q"
      },
      "source": [
        "from openimages.download import download_images\n",
        "import os\n",
        "import shutil"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cpArE43J8bB"
      },
      "source": [
        "# removes every directory from the directory given in the parameter\n",
        "def clear_workdir(workdir):\n",
        "  for filename in os.listdir(workdir):\n",
        "    filepath = os.path.join(workdir, filename)\n",
        "    if os.path.isdir(filepath):\n",
        "      shutil.rmtree(filepath)\n",
        "\n",
        "# creates empty directories for training, validation and testing data\n",
        "def make_set_directory(set_name, classes):\n",
        "  os.mkdir(set_name)\n",
        "  for cls in classes:\n",
        "    os.mkdir(os.path.join(set_name, cls))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXU5TO100_EX"
      },
      "source": [
        "The download_images() function download 600 pictures of each category to the /[category]/images folder. We'd like to move these pictures into folders reserved for training/validation/testing for each category.\n",
        "\n",
        "To make the file structure transparent (easy to see through) I also remove the unneeded folders after moving all the pictures to the proper location. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmY0L4ro5rhR",
        "outputId": "a835cd60-97f3-4076-c533-adca028b0fa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "workdir = os.getcwd()\n",
        "clear_workdir(workdir)\n",
        "\n",
        "# These are the classes I selected for the exercise..\n",
        "# For whatever reason download_images() fails if I don't\n",
        "# use upper case for the initial letter of the class' strings\n",
        "classes = [\"Car\", \"Bus\", \"Train\"]\n",
        "download_images(workdir, classes, exclusions_path=None, limit=600)\n",
        "\n",
        "# Converts class strings to lowercase letters\n",
        "# as download_images() make dirs with only lowercase names\n",
        "for i in range(len(classes)):\n",
        "  classes[i] = classes[i].lower()\n",
        "\n",
        "set_dirs = [\"training\", \"validation\", \"testing\"]\n",
        "for set_dir in set_dirs:\n",
        "  make_set_directory(set_dir, classes)\n",
        "\n",
        "nb_training = 400\n",
        "nb_validation = 100\n",
        "nb_testing = 100\n",
        "\n",
        "for cls in classes:\n",
        "  path_to_class = os.path.join(cls, \"images\")\n",
        "  for i, filename in enumerate(os.listdir(path_to_class)):\n",
        "    full_path_to_pic = os.path.join(path_to_class, filename)\n",
        "    if i < nb_training:\n",
        "      shutil.move(full_path_to_pic, os.path.join(workdir, set_dirs[0], cls, filename))\n",
        "    elif i < nb_training + nb_validation:\n",
        "      shutil.move(full_path_to_pic, os.path.join(workdir, set_dirs[1], cls, filename))\n",
        "    else:\n",
        "      shutil.move(full_path_to_pic, os.path.join(workdir, set_dirs[2], cls, filename))\n",
        "  \n",
        "  # we moved every picture to our train/valid/test set\n",
        "  # so we can delete the empty directory\n",
        "  shutil.rmtree(os.path.join(workdir, cls))\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-08  18:58:25 INFO NumExpr defaulting to 2 threads.\n",
            "2020-11-08  18:58:27 INFO Downloading 600 train images for class 'car'\n",
            "100%|██████████| 600/600 [00:13<00:00, 43.90it/s]\n",
            "2020-11-08  18:58:41 INFO Downloading 600 train images for class 'bus'\n",
            "100%|██████████| 600/600 [00:13<00:00, 44.14it/s]\n",
            "2020-11-08  18:58:55 INFO Downloading 600 train images for class 'train'\n",
            "100%|██████████| 600/600 [00:13<00:00, 44.62it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Nodr5gqhsmf"
      },
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, History, EarlyStopping"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVgnFxmq2YA4"
      },
      "source": [
        "As loading every picture would probably cause memory problems in colab I used generators for training and testing. As a **preprocessing function** I used the one I found in the inception_v3 module, hopefully correctly.  \n",
        "\n",
        "At the end of this cell as an output we can see that our training set, validation set and training set contains 3x400, 3x100, 3x100 images respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2WJmehnbMaY",
        "outputId": "28f718e4-13a0-45eb-84ad-d4984e120585",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "img_height = 256     # Input image height\n",
        "img_width  = 256     # Input image width\n",
        "batch_size = 32\n",
        "class_mode = 'categorical'\n",
        "color_mode = 'rgb' \n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_iter = train_datagen.flow_from_directory(\n",
        "    os.path.join(workdir, set_dirs[0]),\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = class_mode,\n",
        "    color_mode = color_mode\n",
        ")\n",
        "\n",
        "validation_iter = train_datagen.flow_from_directory(\n",
        "    os.path.join(workdir, set_dirs[1]),\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = class_mode,\n",
        "    color_mode = color_mode\n",
        ")\n",
        "\n",
        "test_iter = test_datagen.flow_from_directory(\n",
        "    os.path.join(workdir, set_dirs[2]),\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size = 1,\n",
        "    class_mode = class_mode,\n",
        "    color_mode = color_mode\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1200 images belonging to 3 classes.\n",
            "Found 300 images belonging to 3 classes.\n",
            "Found 300 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-Ox3GtT5mmo"
      },
      "source": [
        "Creating the base model from the InceptionV3 template, with weights initialized according to imagenet.\n",
        "\n",
        "I added a custom fully connected layer to the end.\n",
        "\n",
        "Additionally, I defined two callbacks: one for model saving and one for early stopping for the case when the training fails to improve validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-VLnlnAfEqk",
        "outputId": "43be8bd9-9e18-4ed3-b3c9-f5ff0d250c2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_model = InceptionV3(input_shape=(img_height, img_width, 3),\n",
        "                    weights=\"imagenet\",\n",
        "                    include_top=False,\n",
        "                    classes=3)\n",
        "\n",
        "inputs = Input(shape=(img_height, img_width, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(32, activation=\"relu\")(x)\n",
        "x = Dense(64, activation=\"relu\")(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(32, activation=\"relu\")(x)\n",
        "outputs = Dense(3, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "estopping = EarlyStopping(monitor=\"val_acc\", patience=7, verbose=1)\n",
        "checkpoint = ModelCheckpoint(\"chk.chk\", save_weights_only=True, save_best_only=True, monitor=\"val_acc\", verbose=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF2wyp706zR2"
      },
      "source": [
        "Train the model's fully connected part by disabling the **base_model**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmTh8MupjVGY",
        "outputId": "44cd54c6-cb54-4b2a-96c7-cc01d45a33ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
        "\n",
        "model.fit(\n",
        "    train_iter,\n",
        "    epochs=30,\n",
        "    validation_data=validation_iter,\n",
        "    callbacks=[checkpoint, estopping]) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.8868 - acc: 0.6150\n",
            "Epoch 00001: val_acc improved from -inf to 0.91000, saving model to chk.chk\n",
            "38/38 [==============================] - 40s 1s/step - loss: 0.8868 - acc: 0.6150 - val_loss: 0.5184 - val_acc: 0.9100\n",
            "Epoch 2/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5004 - acc: 0.8467\n",
            "Epoch 00002: val_acc improved from 0.91000 to 0.92333, saving model to chk.chk\n",
            "38/38 [==============================] - 38s 1s/step - loss: 0.5004 - acc: 0.8467 - val_loss: 0.3077 - val_acc: 0.9233\n",
            "Epoch 3/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3861 - acc: 0.8800\n",
            "Epoch 00003: val_acc improved from 0.92333 to 0.92667, saving model to chk.chk\n",
            "38/38 [==============================] - 38s 999ms/step - loss: 0.3861 - acc: 0.8800 - val_loss: 0.2559 - val_acc: 0.9267\n",
            "Epoch 4/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3415 - acc: 0.8858\n",
            "Epoch 00004: val_acc did not improve from 0.92667\n",
            "38/38 [==============================] - 38s 987ms/step - loss: 0.3415 - acc: 0.8858 - val_loss: 0.2654 - val_acc: 0.9133\n",
            "Epoch 5/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3062 - acc: 0.9017\n",
            "Epoch 00005: val_acc did not improve from 0.92667\n",
            "38/38 [==============================] - 37s 985ms/step - loss: 0.3062 - acc: 0.9017 - val_loss: 0.2537 - val_acc: 0.9000\n",
            "Epoch 6/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2862 - acc: 0.8983\n",
            "Epoch 00006: val_acc improved from 0.92667 to 0.94333, saving model to chk.chk\n",
            "38/38 [==============================] - 38s 1s/step - loss: 0.2862 - acc: 0.8983 - val_loss: 0.2062 - val_acc: 0.9433\n",
            "Epoch 7/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2816 - acc: 0.9125\n",
            "Epoch 00007: val_acc did not improve from 0.94333\n",
            "38/38 [==============================] - 38s 992ms/step - loss: 0.2816 - acc: 0.9125 - val_loss: 0.2084 - val_acc: 0.9300\n",
            "Epoch 8/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2574 - acc: 0.9142\n",
            "Epoch 00008: val_acc did not improve from 0.94333\n",
            "38/38 [==============================] - 37s 980ms/step - loss: 0.2574 - acc: 0.9142 - val_loss: 0.1943 - val_acc: 0.9367\n",
            "Epoch 9/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2656 - acc: 0.9042\n",
            "Epoch 00009: val_acc did not improve from 0.94333\n",
            "38/38 [==============================] - 37s 986ms/step - loss: 0.2656 - acc: 0.9042 - val_loss: 0.1954 - val_acc: 0.9300\n",
            "Epoch 10/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2436 - acc: 0.9150\n",
            "Epoch 00010: val_acc did not improve from 0.94333\n",
            "38/38 [==============================] - 37s 984ms/step - loss: 0.2436 - acc: 0.9150 - val_loss: 0.2424 - val_acc: 0.9167\n",
            "Epoch 11/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2493 - acc: 0.9183\n",
            "Epoch 00011: val_acc did not improve from 0.94333\n",
            "38/38 [==============================] - 38s 988ms/step - loss: 0.2493 - acc: 0.9183 - val_loss: 0.2234 - val_acc: 0.9233\n",
            "Epoch 12/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2470 - acc: 0.9183\n",
            "Epoch 00012: val_acc improved from 0.94333 to 0.95000, saving model to chk.chk\n",
            "38/38 [==============================] - 38s 994ms/step - loss: 0.2470 - acc: 0.9183 - val_loss: 0.1890 - val_acc: 0.9500\n",
            "Epoch 13/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2556 - acc: 0.9125\n",
            "Epoch 00013: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 988ms/step - loss: 0.2556 - acc: 0.9125 - val_loss: 0.2084 - val_acc: 0.9400\n",
            "Epoch 14/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2306 - acc: 0.9250\n",
            "Epoch 00014: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 988ms/step - loss: 0.2306 - acc: 0.9250 - val_loss: 0.2065 - val_acc: 0.9400\n",
            "Epoch 15/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2376 - acc: 0.9208\n",
            "Epoch 00015: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 37s 985ms/step - loss: 0.2376 - acc: 0.9208 - val_loss: 0.2026 - val_acc: 0.9333\n",
            "Epoch 16/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2279 - acc: 0.9150\n",
            "Epoch 00016: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 37s 978ms/step - loss: 0.2279 - acc: 0.9150 - val_loss: 0.2114 - val_acc: 0.9267\n",
            "Epoch 17/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2214 - acc: 0.9300\n",
            "Epoch 00017: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 1s/step - loss: 0.2214 - acc: 0.9300 - val_loss: 0.1878 - val_acc: 0.9500\n",
            "Epoch 18/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2033 - acc: 0.9375\n",
            "Epoch 00018: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 37s 980ms/step - loss: 0.2033 - acc: 0.9375 - val_loss: 0.1875 - val_acc: 0.9400\n",
            "Epoch 19/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2161 - acc: 0.9275\n",
            "Epoch 00019: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 37s 985ms/step - loss: 0.2161 - acc: 0.9275 - val_loss: 0.2277 - val_acc: 0.9233\n",
            "Epoch 00019: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdf7d249358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnUY1CI17GIX"
      },
      "source": [
        "Now, as we barely see any improvement and has relatively high validation accuracy we can enable training on the InceptionV3 segment (at least on a fraction of it as the exercised asked) without worrying about totally messing up the imagenet's precalculated weights.\n",
        "\n",
        "I make only the upper half of the inception base model trainable.\n",
        "\n",
        "Eventually we load back the best saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQhSMsyljg2T",
        "outputId": "26ce5aaf-558b-439b-9157-e3ec8af3414a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inception_layer_cnt = len(base_model.layers)\n",
        "for i in range(inception_layer_cnt // 2, inception_layer_cnt):\n",
        "  base_model.layers[i].trainable = True\n",
        "\n",
        "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
        "\n",
        "model.fit(\n",
        "    train_iter,\n",
        "    epochs=30,\n",
        "    validation_data=validation_iter,\n",
        "    callbacks=[checkpoint, estopping]) \n",
        "\n",
        "model.load_weights(\"chk.chk\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4843 - acc: 0.8358\n",
            "Epoch 00001: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 41s 1s/step - loss: 0.4843 - acc: 0.8358 - val_loss: 0.2618 - val_acc: 0.9100\n",
            "Epoch 2/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2617 - acc: 0.9108\n",
            "Epoch 00002: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 1s/step - loss: 0.2617 - acc: 0.9108 - val_loss: 0.2192 - val_acc: 0.9233\n",
            "Epoch 3/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2121 - acc: 0.9258\n",
            "Epoch 00003: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 1s/step - loss: 0.2121 - acc: 0.9258 - val_loss: 0.3417 - val_acc: 0.9100\n",
            "Epoch 4/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2119 - acc: 0.9283\n",
            "Epoch 00004: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 1s/step - loss: 0.2119 - acc: 0.9283 - val_loss: 0.2526 - val_acc: 0.9200\n",
            "Epoch 5/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2090 - acc: 0.9417\n",
            "Epoch 00005: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 1s/step - loss: 0.2090 - acc: 0.9417 - val_loss: 0.1888 - val_acc: 0.9300\n",
            "Epoch 6/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2094 - acc: 0.9267\n",
            "Epoch 00006: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 1s/step - loss: 0.2094 - acc: 0.9267 - val_loss: 0.2057 - val_acc: 0.9367\n",
            "Epoch 7/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1690 - acc: 0.9475\n",
            "Epoch 00007: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 1s/step - loss: 0.1690 - acc: 0.9475 - val_loss: 0.2515 - val_acc: 0.9367\n",
            "Epoch 8/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1227 - acc: 0.9650\n",
            "Epoch 00008: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 1s/step - loss: 0.1227 - acc: 0.9650 - val_loss: 0.2165 - val_acc: 0.9200\n",
            "Epoch 9/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1034 - acc: 0.9650\n",
            "Epoch 00009: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 1000ms/step - loss: 0.1034 - acc: 0.9650 - val_loss: 0.2219 - val_acc: 0.9400\n",
            "Epoch 10/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1674 - acc: 0.9483\n",
            "Epoch 00010: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 1s/step - loss: 0.1674 - acc: 0.9483 - val_loss: 0.1728 - val_acc: 0.9500\n",
            "Epoch 11/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0943 - acc: 0.9708\n",
            "Epoch 00011: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 1s/step - loss: 0.0943 - acc: 0.9708 - val_loss: 0.2351 - val_acc: 0.9267\n",
            "Epoch 12/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0904 - acc: 0.9717\n",
            "Epoch 00012: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 1s/step - loss: 0.0904 - acc: 0.9717 - val_loss: 0.2340 - val_acc: 0.9467\n",
            "Epoch 13/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1516 - acc: 0.9508\n",
            "Epoch 00013: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 1s/step - loss: 0.1516 - acc: 0.9508 - val_loss: 0.3070 - val_acc: 0.9300\n",
            "Epoch 14/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2739 - acc: 0.9242\n",
            "Epoch 00014: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 1s/step - loss: 0.2739 - acc: 0.9242 - val_loss: 0.3576 - val_acc: 0.8767\n",
            "Epoch 15/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2216 - acc: 0.9242\n",
            "Epoch 00015: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 1s/step - loss: 0.2216 - acc: 0.9242 - val_loss: 0.2536 - val_acc: 0.9233\n",
            "Epoch 16/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0757 - acc: 0.9800\n",
            "Epoch 00016: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 38s 998ms/step - loss: 0.0757 - acc: 0.9800 - val_loss: 0.2611 - val_acc: 0.9467\n",
            "Epoch 17/30\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0637 - acc: 0.9792\n",
            "Epoch 00017: val_acc did not improve from 0.95000\n",
            "38/38 [==============================] - 39s 1s/step - loss: 0.0637 - acc: 0.9792 - val_loss: 0.4068 - val_acc: 0.8933\n",
            "Epoch 00017: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fdf7a590ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHuAsgRNBUyp"
      },
      "source": [
        "Let's see how our model performs now on the test set.  \n",
        "We interested in the returned accuracy value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTsviHb2kBG9",
        "outputId": "5dbe2aca-e48f-4d85-c696-6e42983abbdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loss, acc = model.evaluate(test_iter)\n",
        "print(acc)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300/300 [==============================] - 6s 19ms/step - loss: 0.2110 - acc: 0.9500\n",
            "0.949999988079071\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}