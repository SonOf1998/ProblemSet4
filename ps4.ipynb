{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNuob02c7PiNh9K605VyhtH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SonOf1998/ProblemSet4/blob/main/ps4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12d3fx_kHIrn"
      },
      "source": [
        "First install the package that makes it easy to get the required images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVxZMlVz5Qh6",
        "outputId": "b448142d-bc77-4c99-c04e-13c5e7145e77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install openimages"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openimages in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from openimages) (4.41.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from openimages) (1.1.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from openimages) (4.2.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from openimages) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from openimages) (1.16.13)\n",
            "Requirement already satisfied: cvdata in /usr/local/lib/python3.6/dist-packages (from openimages) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->openimages) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->openimages) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas->openimages) (1.18.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->openimages) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->openimages) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->openimages) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->openimages) (2020.6.20)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->openimages) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.20.0,>=1.19.13 in /usr/local/lib/python3.6/dist-packages (from boto3->openimages) (1.19.13)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->openimages) (0.10.0)\n",
            "Requirement already satisfied: ImageHash in /usr/local/lib/python3.6/dist-packages (from cvdata->openimages) (4.1.0)\n",
            "Requirement already satisfied: tensorflow-cpu>=2.1 in /usr/local/lib/python3.6/dist-packages (from cvdata->openimages) (2.3.1)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from cvdata->openimages) (0.5.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from cvdata->openimages) (4.1.2.30)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from cvdata->openimages) (7.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->openimages) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from ImageHash->cvdata->openimages) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.6/dist-packages (from ImageHash->cvdata->openimages) (1.1.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (0.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (1.1.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (0.3.3)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (0.35.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (2.3.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (2.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (1.33.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (3.3.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu>=2.1->cvdata->openimages) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow-cpu>=2.1->cvdata->openimages) (50.3.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (0.4.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (2.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-cpu>=2.1->cvdata->openimages) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ox24f8e5j1q"
      },
      "source": [
        "from openimages.download import download_images\n",
        "import os\n",
        "import shutil"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cpArE43J8bB"
      },
      "source": [
        "# removes every directory from the directory given in the parameter\n",
        "def clear_workdir(workdir):\n",
        "  for filename in os.listdir(workdir):\n",
        "    filepath = os.path.join(workdir, filename)\n",
        "    if os.path.isdir(filepath):\n",
        "      shutil.rmtree(filepath)\n",
        "\n",
        "# creates empty directories for training, validation and testing data\n",
        "def make_set_directory(set_name, classes):\n",
        "  os.mkdir(set_name)\n",
        "  for cls in classes:\n",
        "    os.mkdir(os.path.join(set_name, cls))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmY0L4ro5rhR",
        "outputId": "6d5a3d29-ca9c-4c77-8419-0abdabe065e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "workdir = os.getcwd()\n",
        "clear_workdir(workdir)\n",
        "\n",
        "# These are the classes I selected for the exercise..\n",
        "# For whatever reason download_images() fails if I don't\n",
        "# use upper case for the initial letter of the class' strings\n",
        "classes = [\"Car\", \"Bus\", \"Train\"]\n",
        "download_images(workdir, classes, exclusions_path=None, limit=600)\n",
        "\n",
        "# Converts class strings to lowercase letters\n",
        "# as download_images() make dirs with only lowercase names\n",
        "for i in range(len(classes)):\n",
        "  classes[i] = classes[i].lower()\n",
        "\n",
        "set_dirs = [\"training\", \"validation\", \"testing\"]\n",
        "for set_dir in set_dirs:\n",
        "  make_set_directory(set_dir, classes)\n",
        "\n",
        "nb_training = 400\n",
        "nb_validation = 100\n",
        "nb_testing = 100\n",
        "\n",
        "for cls in classes:\n",
        "  path_to_class = os.path.join(cls, \"images\")\n",
        "  for i, filename in enumerate(os.listdir(path_to_class)):\n",
        "    full_path_to_pic = os.path.join(path_to_class, filename)\n",
        "    if i < nb_training:\n",
        "      shutil.move(full_path_to_pic, os.path.join(workdir, set_dirs[0], cls, filename))\n",
        "    elif i < nb_training + nb_validation:\n",
        "      shutil.move(full_path_to_pic, os.path.join(workdir, set_dirs[1], cls, filename))\n",
        "    else:\n",
        "      shutil.move(full_path_to_pic, os.path.join(workdir, set_dirs[2], cls, filename))\n",
        "  \n",
        "  # we moved every picture to our train/valid/test set\n",
        "  # so we can delete the empty directory\n",
        "  shutil.rmtree(os.path.join(workdir, cls))\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-08  15:13:12 INFO Downloading 600 train images for class 'car'\n",
            "100%|██████████| 600/600 [00:13<00:00, 43.54it/s]\n",
            "2020-11-08  15:13:26 INFO Downloading 600 train images for class 'bus'\n",
            "100%|██████████| 600/600 [00:13<00:00, 43.10it/s]\n",
            "2020-11-08  15:13:40 INFO Downloading 600 train images for class 'train'\n",
            "100%|██████████| 600/600 [00:13<00:00, 44.18it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Nodr5gqhsmf"
      },
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, History, EarlyStopping"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2WJmehnbMaY",
        "outputId": "cd0f365d-7edb-4a7f-de78-f53928eb1973",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "img_height = 256     # Input image height\n",
        "img_width  = 256     # Input image width\n",
        "batch_size = 32\n",
        "class_mode = 'categorical'\n",
        "color_mode = 'rgb' \n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_iter = train_datagen.flow_from_directory(\n",
        "    os.path.join(workdir, set_dirs[0]),\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = class_mode,\n",
        "    color_mode = color_mode\n",
        ")\n",
        "\n",
        "validation_iter = train_datagen.flow_from_directory(\n",
        "    os.path.join(workdir, set_dirs[1]),\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = class_mode,\n",
        "    color_mode = color_mode\n",
        ")\n",
        "\n",
        "test_iter = test_datagen.flow_from_directory(\n",
        "    os.path.join(workdir, set_dirs[2]),\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size = 1,\n",
        "    class_mode = class_mode,\n",
        "    color_mode = color_mode\n",
        ")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1200 images belonging to 3 classes.\n",
            "Found 300 images belonging to 3 classes.\n",
            "Found 300 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-VLnlnAfEqk"
      },
      "source": [
        "base_model = InceptionV3(input_shape=(img_height, img_width, 3),\n",
        "                    weights=\"imagenet\",\n",
        "                    include_top=False,\n",
        "                    classes=3)\n",
        "\n",
        "inputs = Input(shape=(img_height, img_width, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "x = Dense(512, activation=\"relu\")(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "outputs = Dense(3, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"chk.chk\", save_weights_only=True, save_best_only=True, monitor=\"val_accuracy\", verbose=1)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmTh8MupjVGY",
        "outputId": "7679ff53-8467-4330-9c24-81a36dd36030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "base_model.trainable = False\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"acc\"])\n",
        "\n",
        "model.fit(\n",
        "    train_iter,\n",
        "    epochs=30,\n",
        "    validation_data=validation_iter,\n",
        "    callbacks=[checkpoint]) "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cc47039203d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rmsprop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model.fit(\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'base_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQhSMsyljg2T"
      },
      "source": [
        "base_model.trainable = True\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"acc\"])\n",
        "\n",
        "model.fit(\n",
        "    train_iter,\n",
        "    epochs=30,\n",
        "    validation_data=validation_iter,\n",
        "    callbacks=[checkpoint]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTsviHb2kBG9"
      },
      "source": [
        "loss, acc = model.evaluate(test_iter)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}